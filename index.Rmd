---
title: "performr vignette"
author: "Silas Tittes"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output: html_document
---

NOTE: This document is in progress. Feel free to suggest changes on the package's [GitHub page](https://github.com/silastittes/performr), or by email <silas.tittes@gmail.com>.

How to use `performr` package
===============

```{r, echo=FALSE}
#load library
suppressWarnings(suppressMessages(library(performr)))
suppressMessages(library(ggridges))
theme_set(theme_minimal())

knitr::opts_chunk$set(fig.align = "center")


```


`performr` implements a probabilistic Bayesian hierarchical model (using [Stan](http://mc-stan.org/)) to predict tolerance/performance curves for a set of input taxa. The manuscript that describes the method is in revision. This page is intended to help those interested in using the model for their own data.

Installation
---------------

Installing `performr` is done using the following command:
```{r, eval=FALSE}
#install
devtools::install_github("silastittes/performr", local = FALSE)

#load other libraries used below
library(performr)
library(tidyverse)
library(ggridges)
theme_set(theme_minimal())
```

As the model is written in Stan, it requires a c++ compiler. For Apple and PC users, you likely need to install one. If the installation command above fails, Mac users can open their terminal and type:

```{r, engine='bash', eval = F}
xcode-select --install
```

This should open some dialogue to install the Xcode developer tools. Follow the prompts to install. Once the install finishes, try the `install_github()` command again. At this point, I have not tested the package on PCs, but I would guess a similar step is required (please email me if you have success on a PC!).

Linux users can likely run the command as-is, or by using `devtools::install_github("silastittes/performr")`, which would use the pre-compiled version that my Linux machine built (Linux Mint 18.3). 

Last installation detail, `performr` depends on several packages. These can take some time to install, but usually goes smoothly as long as your R is up to date! If you run into troubles, check the R session info at the bottom of this page. Compare to your own session info for missing packages and older package versions.


Simulating example data 
---------------

For demonstration and model validation, data can be simulated from the hyperpriors. The true parameter values for both hyper parameters and species-level parameters are returned in addition to a simulated data frame. All arguments have defaults, but fiddling with parameter values is encouraged. 

I'll demonstrate a data set with three species, 20 positions sampled along an environmental axis, and three replicates per species at each position along the axis (wouldn't that be something):
```{r}
set.seed(223524)
perf_df <- simulate_data(n_spp = 3, n_axis = 20, n_reps = 3)
```


Here are a few quick ways to look at the output:
```{r, fig.cap="Simulated data for three 'species' plotted with the curves used to generate the samples."}
head(perf_df$sim_data)

str(perf_df)

perf_df$sim_data %>%
  mutate(species = factor(species)) %>%
  ggplot(aes(x, trait, colour = species)) +
  geom_point() +
  geom_line(aes(x, mu))
```

There are 3 columns of input data required to run the model, where each row represents an individual unit of sampling (name and order the columns as you please): 

- Integers representing the groups (or "species") each sample belongs to -- even if there is only one group.

- An x-axis consisting of measurements from some environmental variable (soil moisture, temperature, etc.).

- A measure of performance for each individual studied in that environmental condition (trait). *Rows with missing values must be removed before fitting* -- `tidyr::drop_na()` is good for this.

Fitting the model with `performr::stan_performance()`
---------------

Now that we have some example data, we can fit the model. Arguments that include "_pr_" are parameters for the priors (for brevity, I will gloss over prior details here and refer readers to the paper once available), which I've set to match the defaults of the simulation (so this is best case scenario for the model getting it right). Notice, I've set a seed to make the results reproducible, and I've reduced the total number of iterations to 200. The default iterations of 2000 (or more) should be used for analysis, but 200 is good for demonstration and troubleshooting purposes.


```{r, eval=FALSE}
perf_out <- 
  stan_performance(
    df = perf_df$sim_data, 
    response = trait, 
    treatment = x, 
    group_ids = species, 
    shape1_pr_mu = 2, 
    shape1_pr_sig = 1, 
    shape2_pr_mu = 2, 
    shape2_pr_sig = 1, 
    stretch_pr_mu = 1, 
    stretch_pr_sig = 1, 
    nu_pr_shape = 8, 
    nu_pr_scale = 3, 
    min_pr_mu = -5, 
    min_pr_sig = 1, 
    max_pr_mu = 5, 
    max_pr_sig = 1,
    iter =  200, 
    seed = 7345, 
    file_id = "stan_example"
  )
```

Although it won't appear on the webpage (the code above is not being evaluated) Stan warns us about the max tree depth (it may also warn about divergent transitions if the simulation is modified). Ideally, those messages should not appear. You can modify the arguments it recommends in  your call to `stan_performance()` as you would if calling Stan directly. Typically, a max_tree_depth between 12 to 14 works well (though slower). The adapt_delta defaults to 0.95, which is sufficient in my experience. Notice the file_id argument, which takes a file prefix for saving the model output to file in your current directory.

We can read in the model from file as such:
```{r}
perf_stan <- 
  rstan::read_stan_csv(
    csvfiles = c(
      "stan_example.samples_1.csv", 
      "stan_example.samples_2.csv", 
      "stan_example.samples_3.csv", 
      "stan_example.samples_4.csv"
    )
  )
```


Output
---------------

The output is the same as any Stan model. 
```{r}
knitr::kable(rstan::summary(perf_stan)$summary, digits = 3)
```


We can access the posterior draws using `rstan::extract()`, which produces a list containing draws for each parameter of the model.
```{r}
draws <- rstan::extract(perf_stan)
ndraws <- length(draws$lp__)
```







There are a lot of good packages out there for visualizing posteriors. I haven't learned any of them yet, but here's a quick approach I'm fond of:
```{r}
#choose parameter
param <- "x_max"

max_df <- draws[[param]] %>%
  as_tibble() %>%
  gather(species, value)

max_df %>%
  ggplot(aes(value, species,  fill = species)) +
  geom_density_ridges(colour = "white") +
  xlab(param) +
  theme(legend.position = "none")
```


Quickly, let's eyeball how these marginal posteriors for the x_max parameter (where performance falls to zero above the optimum) for each species.

```{r}
max_df %>%
  group_by(species) %>%
  summarise(
    cred_025 = quantile(value, 0.025),
    cred_975 = quantile(value, 0.975)
  ) %>%
  mutate(
    truth = perf_df$true_params$x_max
  ) %>%
  mutate(
    within_cred = truth > cred_025 & truth < cred_975
  )
```

Cool, looks like the 95% credible interval captures the true value in each case. It would be easy to extend this approach using a function and quickly verify each parameter. Notice the increased uncertainty in posteriors further from the treatments on the x-axis ... Love that!


Posterior predictive data generation
---------------

The whole concept of posterior prediction and generating data from the model is one of my favorite things about Bayesian statistics. It allows for a lot of creativity in how we check our assumptions. We can generate data from the model using this approach:

First, let's generate a tidy data frame with all the parameters, plus some valuable derived parameters, like the optimum, area, and breadth for each species:
```{r}
head(
  tidy_perf <- 
    perform_df(
      perf_stan, 
      species_order = c(1, 2, 3)
    ) 
)
```




```{r}
#set up sequence from smallest to largest x 
x_seq = seq(min(draws$x_min),
            max(draws$x_max),
            length.out = 100)

#sub-sample draws randomly
poly_draws <- sample(1:ndraws, 100)


test <- 
  predict_interval(
    x = x_seq,
    spp = spp,
    par_df = perf_df,
    x_draws = poly_draws,
    p = c(0.95, 0.5))

test_spp <- test %>%
  filter(spp == unique(test$species)[1])

pred_plot <- ggplot(data = filter(test, level == 95)) +
  facet_wrap(~species, scales = "free_y") +
  geom_ribbon(
    aes(x = x + mean(dro_df$treat_org), 
        ymin = upper, 
        ymax = lower,
        fill = species),
    alpha = 0.3,
    inherit.aes = F) +
  geom_ribbon(
    data = filter(test, level == 50),
    aes(x = x + mean(dro_df$treat_org), 
        ymin = upper, 
        ymax = lower,
        fill = species), 
    inherit.aes = F,
    alpha = 0.7) +
  geom_point(
    data = mutate(dro_df, species = spec_loc), 
    aes(treatment + mean(dro_df$treat_org), 
        sum_n,
        alpha = 0.5), 
    inherit.aes = F,
    colour = "grey70") +
  theme(legend.position = "none")

```





Now we can generate pseudo observed data from the posterior draws. 
```{r}
tidy_perf %>%
  filter(draw == 1) %>%
  posterior_predict(par_df = .) %>%
  head()
```

By default, the x-axis will be constructed as a sequence of 100 values that start from the minimum posterior draw value of x_min and end at the maximum of x_max. This default can be changed using the x argument. Filtering for posterior draws is not required before using the function -- posterior predictive data will be produced for every posterior draw passed to `par_df`.

If you have questions, comments, or concerns, please get in touch. I would be excited to discuss! 


<button data-toggle="collapse" data-target="#sessioninfo" class="btn btn-primary btn-md btn-info> R session info</button>

<div id="sessioninfo" class="collapse">

```{r}
writeLines(readLines(file.path(Sys.getenv("HOME"), ".R/Makevars")))

devtools::session_info()
```

</dev>